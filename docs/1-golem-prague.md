---
title: "Chapter 1: The Golem of Prague"
description: "Chương 1: Golem xứ sở Prague"
---

- [1.1 Những con Golem thống kê](#a1)
- [1.2 Suy nghĩ lại thống kê](#a2)
- [1.3 Các công cụ để tạo golem](#a3)
- [1.4 Tổng kết](#a4)

Vào thế kỷ thứ 16, gia tộc Habsburg kiểm soát hầu như toàn bộ Châu Âu, Hà Lan, Tây Ban Nha, và cả thuộc địa Tây Ban Nha tại Mỹ. Gia tộc này có lẽ là sức mạnh lớn nhất thế giới lúc bấy giờ. Mặt trời luôn toả sáng ở một phần của gia tộc họ. Người đứng đầu là Đức vua Holy Roman, và quyền lực của ông nằm ở Prague. Đức vua vào cuối thế kỷ 16, Rudolph II, rất thích sự thông minh. Ông đầu tư vào nghệ thuật, khoa học (bao gồm thiên văn học và giả kim thuật), toán học, hình thành nên Prague, trung tâm thế giới về giáo dục và kiến thức. Trong môi trường học thuật này thì rất sớm để sản sinh ra con robot đầu tiên, Golem xứ sở Prague.

Một con Golem là một robot đất sét trong cổ tích Do Thái, làm từ đất, nước và lửa. Nó được tạo ra bởi dấu ấn *'emet'*, "sự thật" trong tiếng Do Thái, trên lông mày của nó. Được hoạt động bởi sự thật, nhưng không có tự suy nghĩ, nên con golem luôn hành động theo sắp đặt của người chủ. Điều này thực may mắn, vì golem rất mạnh, có khả năng chịu đựng tốt và làm việc nhiều hơn chủ nhân của nó. Tuy nhiên, sự vâng lời cũng đi kèm với nguy hiểm, vì sự chỉ dẫn bất cẩn hoặc biến cố không mong muốn sẽ làm cho golem chống lại chính chủ nhân. Sức mạnh khủng khiếp của nó đi kèm với sự thiếu hụt trí tuệ.  

Trong một số phiên bản truyền thuyết khác, Rabbi Judah Loew ben Bezalel tìm một cách để bảo vệ người Do Thái ở Prague. Cũng như nhiều nơi khác của Trung Âu thế kỷ 16, người Do Thái ở Prague bị khinh ghét. Bằng những kỹ năng trong *Kabbalah*, Rabbi Judah đã tạo ra một con golem, hoạt động bởi "sự thật", và ra lệnh cho nó bảo vệ người Do Thái Prague. Không ai đồng tình với hành động của Judah, sợ hãi những hậu quả gây ra do đùa cợt với sự sống. Cuối cùng Judah bị ép buộc phá huỷ con golem, vì sự kết hợp của sức mạnh và hậu đậu từ từ cũng dẫn đến nhiều cái chết vô tội. Bằng cách xoá một ký tự trong dấu ấn *'emet'*, trở đọc thành *'met'*, "cái chết", Rabbi Judah đã tháo gỡ con robot ấy.  

## <center>1.1 Những con Golem thống kê</center><a name="a1"></a>

Trong khoa học, người ta cũng làm Golem.<sup><a name="r1" href="#1">1</a></sup> Golem đó không có hình dạng vật lý, mà vẫn được tạo ra từ đất sét, sống dưới hình hài của silicon và các đoạn mã code. Chúng là mô hình khoa học. Nhưng những golem này có ảnh hưởng thực đến thế giới bên ngoài, thông qua các dự đoán và cảm tính chúng nó tạo ra hoặc khơi gợi. Mối liên hệ với "sự thật" luôn tồn tại trong những mô hình này, nhưng cũng giống như golem hay một robot hiện đại khác, mô hình khoa học không đúng và không sai, không phải nhà tiên tri hay lừa đảo. Chẳng qua chúng là những cổ máy được thiết lập cho một số mục đích. Những cổ máy này rất mạnh, luôn tuân theo phép tính lập trình sẵn.

Đôi khi những logic của chúng giúp khám phá ra những giá trị bị ẩn đi. Những giá trị đó có thể là phát hiện vô giá. Hoặc chúng tạo ra những hành vi ngớ ngẩn và nguy hiểm. Thay vì là những thiên thần được lý tưởng hoá để suy luận, mô hình khoa học là golem đất sét mạnh mẽ không có tự suy nghĩ, hoạt động răm rắp theo những lệnh lập trình. Giống như Golem trong câu chuyện Rabbi Judah, golem trong khoa học rất mạnh mẽ và cũng đầy rủi ro. Chúng ta chắc chắn phải dùng chúng, nhưng phải nhận ra nguy cơ đi theo.

Có rất nhiều mô hình thống kê trong khoa học. Khi một ai muốn sử dụng quy trình thống kê đơn giản, như *t*-test, tức là người đó đang dùng một con golem tính toán chính xác theo các lệnh có sẵn, cùng một quy trình cho (hầu như<sup><a name="r2" href="#2">2</a></sup>) mọi trường hợp, không một lời phàn nàn. Hầu như mọi nhánh của khoa học đều dựa vào giác quan của golem thống kê. Trong nhiều trường hợp, việc đo dạc hiện tượng đang tìm hiểu, mà không cần golem, là bất khả thi. Ví dụ:
- Cường độ của chọn lọc tự nhiên.
- Tốc độ của neutrino.
- Số lượng các loài trong rừng Amazon.

Golem là một vật thể nhân tạo, giúp đo lường, thực hiện phép tính nhanh chóng, tìm kiếm những dấu hiệu trong khi ta không nhận ra.

Tuy nhiên, mô hình thống kê không có nhận thức, nó không phân biệt được là bối cảnh này có phù hợp với khả năng của nó hay không, nó chỉ biết thực hiện quy trình, không gì hơn. Nó làm việc theo những gì nó được chỉ bảo. Và khoa học ngày nay tồn tại rất nhiều và đa dạng các golem này. Mỗi con được sử dụng trong một bối cảnh cụ thể. Với góc nhìn này, thống kê không còn là toán học hay khoa học, mà là một nhánh của kỹ thuật. Trong kỹ thuật, có một tập hợp phổ biến của các nguyên tắc và giới hạn trong thiết kế đi liền với nhiều dạng cách sử dụng chuyên biệt khác nhau.  

Chính sự đa dạng này giải thích tại sao thống kê thường rối tung lên cho người mới bắt đầu học. Thay vì một phương pháp dùng để xây dựng, tinh chỉnh, lượng giá mô hình, học sinh được thầy cô bày ra một khu rừng các golem thống kê có sẵn được gọi là "phép kiểm". Mỗi phép kiểm có một dụng ý khác nhau. Cây quyết định như [**HÌNH 1.1**](#f1) là một ví dụ. Bằng cách trả lời các câu hỏi nối tiếp nhau, người sử dụng sẽ chọn được phương pháp "đúng" trong tình huống nghiên cứu của họ.

<a name="f1"></a>![](/assets/images/fig 1-1.png)
<details class="fig"><summary>Hình 1.1: Ví dụ cây quyết định, hay lưu đồ, để chọn một quy trình thống kê thích hợp. Từ trên cùng, người dùng trả lời những câu hỏi về đo lường và ý định, đích đến là tên của quy trình. Tồn tại rất nhiều cây quyết định như vậy.</summary></details>

Đáng tiếc rằng, trong khi chỉ những người thống kê có kinh nghiệm thì nắm vững dụng ý của những phép kiểm này, học sinh và người làm nghiên cứu thì không. Các khoá học nâng cao có nhấn mạnh nguyên tắc kỹ thuật, nhưng họ không đi xa được như vậy. Việc dạy thống kê theo cách này giống như dạy kỹ thuật theo hướng lùi ngược, bắt đầu bằng xây cầu và kết thúc bằng vật lý cơ bản. Cho nên học sinh và người làm nghiên cứu thường dùng những bảng như [**HÌNH 1.1**](#f1) mà không cần đặt nhiều suy nghĩ vào cấu trúc cơ bản của mô hình, không nhận thức được những quy trình mà mô hình ứng dựa trên đó, và không có một bộ khung công cụ nào giúp họ tránh được những sai sót khi áp dụng trên thí nghiệm thực tế. Đây không phải lỗi họ.  

Đối với đa số, công cụ có sẵn là thứ duy nhất họ cần. Cho rằng chúng được sử dụng đúng mục đích, đúng bối cảnh, khoa học đúng vẫn khả thi. Điều này giống như thợ sửa ống nước vẫn làm việc được mà không cần biết thuỷ động học. Vấn đề nghiêm trọng bắt đầu khi nhà khoa học thực hiện những nghiên cứu đột phá, thúc đẩy giới hạn của chuyên môn bản thân. Việc này giống như thăng chức thợ sửa ống nước thành nhà khoa học thuỷ lực.

Tại sao các test này không đủ cho nghiên cứu mới? Mô hình thống kê cổ điển thường không linh hoạt và mỏng manh.
1. Không linh hoạt, nghĩa là có rất ít phương pháp để phù hợp với tình cảnh nghiên cứu đặc biệt.
2. Mỏng manh, nghĩa là quy trình ấy không lường trước được thất bại khi áp dụng vào một tình cảnh mới.

Điều này đáng quan tâm, bởi vì trong khoa học, không bao giờ rõ ràng mô hình nào là phù hợp nhất. Ví dụ điển hình là Fisher's exact test, được áp dụng chỉ trong những tình cảnh rất hạn chế, nhưng lại được dùng đại trà mỗi khi mẫu số ít. Hoặc hồi quy tuyến tính OLS (ordinary linear regression) khá linh hoạt theo nhiều hướng, có thể mô hình hoá nhiều giả thuyết thú vị, nhưng đôi khi nó vẫn mỏng manh. Ví dụ, nếu có một sai số đo lường ở những biến dự đoán, thì cả quy trình có thể thất bại một cách ngoạn mục. Quan trọng hơn, vẫn có mô hình OLS tốt hơn vì có hiện tượng **OVERFITTING**.

Vấn đề không phải do những công cụ thống kê bị chuyên biệt hoá. Vốn dĩ nó đã là như vậy. Vấn đề là những công cụ cổ điển không đủ độ đa dạng để xử lý nhiều câu hỏi nghiên cứu thông thường. Mỗi lĩnh vực khoa học đi kèm với sự riêng biệt trong đo lường và diễn giải, đối thoại chỉ được hiểu hết chỉ khi với người cùng ngành. Người làm thống kê ngoài ngành có thể giúp, nhưng bị ảnh hưởng vì giới hạn kiến thức trong ngành.

Hơn nữa, không công cụ thống kê nào có thể tự mình nó nói ra được vấn đề cơ bản trong suy luận nhân quả từ bằng chứng. Golem thống kê không hiểu nguyên nhân và hiệu ứng. Chúng chỉ biết tương quan. Nếu không có sự chỉ dẫn và nghi ngại của chúng ta, những con golem dựng sẵn có thể không giúp được gì cả. Thậm chí, nó có thể phá nát Prague.

Những gì nhà nghiên cứu cần là một lý thuyết nhất quán trong thiết kế golem, một tập hợp nguyên tắc trong thiết kế, xây dựng, tinh chỉnh những quy trình thống kê vào mục đích riêng biệt. Mọi nhánh của triết lý thống kê đều tồn tại một thuyết nhất quán. Nhưng thuyết này không bao giờ được dạy trong các khoá học cơ bản - hoặc khoá học nâng cao. Cho nên bạn sẽ có lợi từ việc suy nghĩ lại suy luận thống kê như là một tập hợp các chiến lược, hơn là những công cụ dựng sẵn.

## <center>1.2 Suy nghĩ lại thống kê</center><a name="a2"></a>

Rất nhiều sai sót xảy ra trong suy luận thống kê, và đây là một nguyên nhân gây lo lắng cho người mới bắt đầu. Khi mục tiêu là chọn một phép kiểm định dựng sẵn từ bảng kiểm như trên, thì sự lo lắng có thể là phép kiểm định đó có "đúng" hay không. Nhà thống kê, trong vai trò của họ, có thể cảm thấy hạnh phúc từ việc chê bai nhà khoa học, càng làm cho cuộc chiến tâm lý nặng nề hơn.

Nhưng sự lo lắng cũng có thể được tôi luyện thành tri thức. Đó là lý do sách này tập trung vào các phép tính nhỏ nhặt của mỗi golem. Nếu bạn không hiểu cách golem xử lý thông tin, bạn không thể diễn giải kết quả từ nó. Ta cần thiết phải hiểu mô hình ở mức độ chi tiết hơn, cần phải thực hiện phép tính ở dạng thô nhất, ít ra bạn đủ kiến thức để sử dụng giải pháp "nhấn nút".

Theo lý thuyết, có những chướng ngại vật trong thống kê, như định nghĩa mục tiêu thống kê và cách diễn giải kết quả thống kê. Hiểu biết từng con golem riêng rẽ là chưa đủ, trong trường hợp này. Thay vào đó, chúng ta cần nằm rõ kiến thức tổng quát, mối liên hệ giữa mô hình với giả thuyết, và cơ chế hoạt động tự nhiên của hiện tượng nghiên cứu. Vậy ta có thể làm gì với những chiếc máy tính?

Chướng ngại vật lớn nhất có lẽ là người ta quan niệm rằng nhiệm vụ chính của suy luận thống kê là kiểm định giả thuyết vô hiệu.<sup><a name="r3" href="#3">3</a></sup> Đây là suy nghĩ hợp logic, bởi vì Karl Popper quả quyết rằng khoa học phát triển dựa trên phản bác các giả thuyết. Karl Popper (1902-1994) có lẽ là nhà triết học khoa học có tầm ảnh hưởng lớn nhất. Ông ấy đã thuyết phục rằng khoa học phát triển dựa trên xây dựng giả thuyết, mà có thể bị phản bác được. Tìm kiếm những bằng chứng để làm xấu hổ những giả thuyết của chúng ta là một tiêu chuẩn bình thường, và là tiêu chuẩn được đa số các học giả - dù họ có tự cho mình là nhà không học hay không - tuân theo. Vì vậy các quy trình thống kê nên phản bác các giả huyết, nếu chúng ta muốn ở thành nhà khoa học thống kê giỏi.

Nhưng những gì ở trên thuộc tư tưởng Popperism, một hệ tư tưởng khá phổ biến trong giới khoa học nhưng không nằm trong triết lý khoa học. Khoa học không được định nghĩa bởi những công cuộc phản bác, và Popper cũng nhận ra điều đó.<sup><a name="r4" href="#4">4</a></sup> Thực tế, suy luận phản bác là bất khả thi ở hầu hết mọi lĩnh vực khoa học. Có hai lý do có thể nêu ra:
1. Giả thuyết không phải mô hình: mối liên hệ giữa giả thuyết và các loại mô hình khác nhau rất phức tạp. Nhiều mô hình tương ứng với cùng một giả thuyết, và nhiều giả thuyết tương ứng với một mô hình. Điều này làm cho việc phản bác là không khả thi.
2. Ảnh hường từ đo lường: ngay cả khi bạn có data chứng minh được một mô hình là sai, một data khác sẽ phản bác lại phương pháp và kết quả của bạn. Họ không tin tưởng data. Đôi khi họ lại là người đúng.

Bởi hai lý do trên, tư tưởng phản bác giả thuyết là không bao giờ hoạt động được. Phương pháp khoa học không thể rút gọn thành một quy trình thống kê, và phương pháp thống kê cũng không nên giả mạo làm ngơ. Bằng chứng thống kê là một phần của mớ hỗn độn gọi là khoa học, với các cuộc chiến, tự tin thái quá, và đe doạ lẫn nhau. Nếu bạn tin rằng, khoa học đó vẫn có thể hoạt động, thì việc hiểu thêm nó không thể dựa trên tư tưởng phản bác, cũng không thay đổi suy nghĩ của bạn. Nhưng nó giúp bạn thực hiện khoa học tốt hơn. Nó giúp bạn mở mang tầm mắt đến nhiều công dụng hữu ích đúng đắn của golem thống kê.

<div class="alert alert-info">
    <p><strong>Vậy kiểm định giả thuyết vô hiệu có phải thuộc tư tưởng phản bác?</strong> Kiểm định giả thuyết vô hiệu được xem là cùng hệ tư tưởng với Popper. Tuy nhiên, kiểm định giả thuyết vô hiệu dùng để phản bác giả thuyết vô hiệu, không phải là giả thuyết nghiên cứu. Có nghĩa là sự phản bác được đặt lên một gì đó khác ngoài mô hình ban đầu. Có vẻ nó mâu thuẫn với tư tưởng Karl Popper.<sup><a name="r5" href="#5">5</a></sup></p>
</div>

### 1.2.1 Giả thuyết không phải mô hình.

Khi chúng ta thực hiện phản bác một giả thuyết, chúng ta phải làm việc với một mô hình nào đó. Ngay cả bản chất hành động phản bác không phải là thống kê rõ ràng, luôn có một mô hình phía dưới có khả năng đo lường bằng chứng để thực hiện trên giả thuyết. Tất cả mô hình đều sai,<sup><a name="r6" href="#6">6</a></sup> vậy phản bác mô hình có ý nghĩa gì? Điều kiện cần để làm việc với mô hình là phải chấp nhận rằng việc phản bác một giả thuyết là không thể thực hiện được nữa, chỉ vì chúng ta phủ nhận một mô hình có nguồn gốc từ nó.

Hãy khám phá hệ quả này trong bối cảnh ví dụ sinh học quần thể. ([**HÌNH 1.2](#f2)) Ở đầu những năm 1960, có giả thuyết rằng hầu hết mọi tiến hoá do thay đổi tần suất gene được gây ra bởi, không phải do chọn lọc tự nhiên, mà là do đột biến hay [trôi dạt di truyền](https://en.wikipedia.org/wiki/Genetic_drift). Thời ấy ai cũng tin rằng chính chọn lọc tự nhiên đã thiết kế chức năng của sinh vật. Đây là một cuộc tranh luận về chuỗi gene di truyền. Và nhiều thập niên sau đó có nhiều nghiên cứu về mô hình của học thuyết phát triển "trung tính" ở mức phân tử<sup><a name="r7" href="#7">7</a></sup>. Cuộc tranh luận này liên quan nhiều nhất đến Motoo Kimura (1924-1994), thuộc phe mô hình trung tính. Nhiều nhà khoa học di truyền quần thể khác cũng tham gia. Thời gian trôi qua, những phân nhánh khác như sinh thái học cộng đồng,<sup><a name="r8" href="#8">8</a></sup> nhân chủng học<sup><a name="r9" href="#9">9</a></sup> cũng trải qua những phiên bản tranh luận mô hình trung tính riêng biệt của họ.  

<a name="f2"></a>![](/assets/images/fig 1-2.png)
<details class="fig"><summary>Liên quan giữa giả thuyết (trái), mô hình xử lý chi tiết (giữa), và mô hình thống kê (phải), minh họa bởi ví dụ mô hình tiến hóa. Giả thuyết (H) thường là mơ hồ, và tương ứng với nhiều hơn một mô hình xử lý (P). Lượng giá thống kê của giả thuyết hiếm khi nói về mô hình xử lý trực tiếp. Thay vào đó, họ dựa vào mô hình thống kê (M), mà chúng phản ánh chỉ một khía cạnh của mô hình xử lý. Kết quả là, các mối quan hệ là đa phương theo cả hai hướng: giả thuyết không suy ra mô hình độc nhất, và mô hình không suy ra giả thuyết độc nhất. Sự thật này làm cho suy luận thống kê phức tạp hơn nhiều.</summary></details>

Ta sẽ sử dụng lược đồ ở [**HÌNH 1.2**](#f2), ta thấy có 2 giả thuyết: $H_0$ là giả thuyết trung tính, $H_1$ là giả thuyết chọn lọc tự nhiên. Giả thuyết như vậy khá mơ hồ, vì nó được diễn đạt bằng ngôn từ chứ không phải mô hình chính xác. Một giả thuyết có thể có nhiều mô hình xử lý chi tiết khác nhau (process model - là những mô hình dùng để tạo ra kết quả), dựa trên lựa chọn về cấu trúc quần thể, số lượng vị trí, số lượng allen, tỉ lệ đột biến và tái tổ hợp.

Khi ta đã ra các chọn lựa, ta có cột giữa [**HÌNH 1.2**](#f2), mô hình xử lý chi tiết của tiến hoá. Ở đây mô tả những process model nổi bật:<sup><a name="r10" href="#10">10</a></sup>
- $P_{0A}$: Phân phối, kích thước quần thể không thay đổi theo thời gian để đạt một trạng thái hằng định. Ngược lại, $P_{0B}$ là phân phối thay đổi theo thời gian.
- $P_{1A}$: Áp lực chọn lọc tự nhiên trên một allen luôn hằng định theo thời gian. Ngược lại, $P_{1B}$ là áp lực thay đổi trên allen khác nhau theo thời gian.

Một đặc tính quan trọng của nhưng mô hình xử lý này là chúng thể hiện quan hệ nhân quả. Mô hình xử lý khác nhau thể hiện rõ quan hệ giữa nguyên nhân và hiệu ứng. Dù bạn phân tích toán học hay qua mô phỏng, chiều thời gian của mô hình nghĩa là vài thứ là nguyên nhân của vài thứ khác, nhưng không ngược lại. Bạn có thể dùng mô hình này để thực nghiệm, kiểm tra quan hệ nhân quả mà nó đặt ra. Đôi khi những bài kiểm tra này sẽ cho thấy, ngay trước khi có suy luận thống kê, là mô hình không thể giải thích hiện tượng đang đặt nghi vấn.

Để thách thức mô hình xử lý bằng data, ta cần phải dựng lên các mô hình thống kê. Thực không may, mô hình thống kê không thể suy ra quan hệ nhân quả cụ thể. Một mô hình thống kê chỉ thể hiện tương quan giữa các biến số. Kết quả, nhiều mô hình xử lý khác nhau có thể phù hợp với bất kỳ mô hình thống kê nào.

Làm sao để có được mô hình thống kê từ mô hình nhân quả? Một hướng đi là suy ra một phân phối xác suất mong đợi của một đại lượng - a "trị số thống kê" - từ mô hình nhân quả. Ví dụ, trị số thống kê thường gặp trong bối cảnh này là phân phối tần suất (histogram) của tần suất mỗi biến dị gene (allen). Chỉ vài allen hiếm gặp, chỉ xuất hiện ở vài cá thể. Còn lại thì rất thường gặp, xuất hiện ở rất nhiều cá thể trong quần thể. Một kết quả nổi tiếng trong di truyền học quần thể là mô hình như $P_{0A}$ tạo ra phân phối [luỹ thừa (power law)](https://en.wikipedia.org/wiki/Power_law) cho tần suất allen. Cho nên sự thật này cho ra một mô hình thống kê, $M_{II}$, dự đoán phân phối luỹ thừa trong data. Ngược lại, mô hình xử lý với áp lực chọn lọc hằng định $P_{1A}$ cho dự đoán một thứ khác, $M_{III}$.

Thật không may, mô hình chọn lọc khác ($P_{1B}$) cũng rút ra mô hình thống kê tương tự, $M_{II}$, như là mô hình trung tính. Nó cũng tạo ra phân phối luỹ thừa. Cuối cùng ta thấy rằng:
1. Một mô hình thống kê (M)có thể tương ứng một hay nhiều mô hình xử lý (P).
2. Một giả thuyết (H) có thể tương ứng với một hay nhiều mô hình xử lý (P).
3. Một mô hình thống kê (M) có thể tương ứng một hay nhiều giả thuyết (H).

Giờ nhìn xem chuyện gì xảy ra khi so sánh mô hình thống kê với data. Cách cổ điển là lấy mô hình trung tính làm giả thuyết vô hiệu. Nếu data chưa đủ để thuyết phục theo mong đợi, dưới trạng thái của giả thuyết vô hiệu, chúng ta sẽ phủ định giả thuyết vô hiệu. Giả sử ta theo câu chuyện lịch sử của chủ đề này và chọn $P_{0A}$ là giả thuyết vô hiệu. Điều này cho thấy data tương ứng với $M_{II}$. Nhưng bởi vì nó cùng một mô hình thống kê với $P_{1B}$, ta không rõ nên khẳng định hay phủ định giả thuyết vô hiệu. Mô hình vô hiệu này là không độc nhất với bất kỳ mô hình xử lý hay giả thuyết nào. Nếu chúng ta phủ định vô hiệu, ta không thể kết luận áp lực chọn lọc tự nhiên là có hiệu ứng, bởi vì tồn tại giả thuyết trung tính khác cho dự đoán phân phối allen khác hẳn. Và nếu chúng ta không thể phủ định vô hiệu, ta cũng không thể kết luận tiến hoá là trung tính, bởi vì tồn tại mô hình chọn lọc tự nhiên cũng cho phân phối tần suất tương tự.

Đây là một rắc rối lớn. Khi có sơ đồ như [**HÌNH 1.2**](#f2) thì vấn đề rất dễ được nhìn ra. Tuy nhiên chỉ vài người may mắn thôi. Khi giới khoa học quần thể nhận ra vấn đề này, học giả ở phân nhánh khác vẫn còn tiếp tục kiểm định phân phối tần suất với phân phối luỹ thừa, lập luận rằng chỉ có duy nhất một mô hình trung tính.<sup><a name="r11" href="#11">11</a></sup> Ngay cả khi chỉ có một mô hình trung tính, cũng có rất nhiều mô hình không trung tính cho kết quả gần giống với mô hình trung tính, từ đó không thể nào việc phủ định hay việc thất bại phủ định mô hình vô hiệu mà chứa nhiều hiệu năng suy luận được.

Vậy ta có thể làm được gì? Với giả thuyết có nhiều mô hình xử lý, ta có thể làm được nhiều thứ. Thực vậy, nếu nhiều mô hình xử lý cho kết quả giống nhau, bạn phải biết rằng cần tìm một chứng cứ đặc điểm khác, đặc điểm để nhận dạng mô hình xử lý khác nhau. Ví dụ, trong khi $P_{0A}$ và $P_{1B}$ cho cùng một dự đoán phân phối luỹ thừa tương tự nhau cho phân phối tần suất allen, chúng khác nhau về dự đoán phân phối sự thay đổi tần suất allel theo thời gian. Bằng cách so sánh dự đoán của nhiều mô hình thống kê khác nhau, ta có thể tránh được nhiều lỗi ngốc nghếch.

Mô hình thống kê cũng có thể bị nhầm lẫn ở một cách khác, như nhầm lẫn gây ra bởi biến số chưa được quan sát và sai lệch chọn mẫu. Mô hình xử lý cho phép chúng ta thiết kế mô hình thống kê với những vấn đề được đặt ra. Chỉ một mình mô hình thống kê là chưa đủ.

<div class="alert alert-info">
    <p><strong>Entropy và vấn đề xác định mô hình.</strong> Một lý do mà mô hình thống kê thường trùng hợp với nhiều mô hình xử lý chi tiết là bởi vì chúng dựa vào phân phối như normal, binomial, Poisson, và các phân phối khác. Những phân phối này thuộc họ <strong>EXPONENTIAL FAMILY</strong>. Tự nhiên rất ưu ái họ phân phối này. Tự nhiên yêu chúng bởi vì tự nhiên yêu entropy, và tất cả các phân phối họ exponential đều là phân phối <strong>MAXIMUM ENTROPY</strong>. Chương 10 sẽ giải thích rõ thêm tính cách tự nhiên của chúng. Một quan điểm trong thực hành là không một phân phối nào cho khả năng suy luận tốt hơn chúng. Ở một khía cạnh khác, đặc tính maximum entropy của chúng cho phép chúng ta dùng chúng để thực hiện thống kê đơn giản, hữu ích, ngay khi chúng ta không biết mô hình xử lý bên dưới.</p>
</div>

### 1.2.2 Ảnh hưởng từ đo lường

Logic trong khoa học phản bác rất đơn giản. Ta có giả thuyết $H$, cho ra quan sát $D$. Ta tìm quan sát $D$. Nếu không thấy, ta kết luận $H$ sai. Người ta gọi logic này là *'modus tollens'*, trong latinh nghĩa là *phương pháp của sự phá huỷ*. Ngược lại, tìm thấy $D$ không có ý nghĩa gì, bởi vì giả thuyết khác cũng có thể có $D$.  

Có một câu chuyện cổ tích khoa học rất ấn tượng, nó sử dụng *'modus tollens'* để bàn về màu của thiên nga. Trước khi phát hiện Châu Úc, tất cả thiên nga ở Châu Âu đều có lông trắng. Điều này dẫn đến niềm tin là mọi thiên nga đều trắng. Ta biểu diễn bằng giả thuyết:  

$$ H_0: \text{ Mọi thiên nga đều trắng} $$

Khi người Châu Âu đến Châu Úc, họ gặp thiên nga đen. Bằng chứng này cho thấy $H_0$ sai. Thực vậy, không phải mọi thiên nga đều trắng. Có vài con màu đen, theo lời của nhiều người quan sát được. Chìa khoa ở đây là, trước khi đến Châu Úc, không quan sát nào chứng tỏ $H_0$ đúng. Chỉ cần một con đen thì chứng minh nó sai.  

Đây là một câu chuyện hấp dẫn. Nếu ta tin rằng giả thuyết khoa học quan trọng có thể biểu diễn dưới dạng này, thì ta có một phương pháp mạnh để tăng độ chính xác của giả thuyết: tìm một bằng chứng để phủ định giả thuyết của chính mình. Chỉ cần thấy được một con thiên nga đen, $H_0$ là sai.

Việc tìm bằng chứng phủ định rất quan trọng, nhưng nó không rõ ràng như trong chuyện con thiên nga. Cộng thêm, đa số vấn đề khoa học gặp phải cũng không rời rạc nhiều về mặt logic. Thay vào đó, ta thường đối mặt với hai bài toán song song mà làm cho câu chuyện thiên nga bị hiểu sai.
1. Quan sát có thể sai, đặc biệt trong tình huống ở biên giới kiến thức khoa học.
2. Phần lớn giả thuyết là có tính định lượng, đánh giá về mức độ của hiện tượng, hơn là rời rạc, liên quan đến sự hiện diện hay vắng mặt.

#### 1.2.2.1 Quan sát có thể sai

Tất cả người quan sát đều đồng ý rằng dưới điều kiện chung thì một con thiên nga chỉ có đen với trắng. Có vài màu sắc trung gian, và mắt mỗi người quan sát hoạt động vừa đủ để như nhau, để rất ít khi xảy ra bất đồng thuận về màu sắc thiên nga. Nhưng đây không là trường hợp chung trong khoa học, nhất là nhưng khoa học đã trưởng thành. Thay vào đó, chúng ta thường xuyên đối diện với bối cảnh chúng ta tìm ra được một quan sát không thể xác định được. Trong tình huống ở biên giới kiến thức khoa học, khả năng đo lường hiện tượng của giả thuyết cũng như bản chất hiện tượng thường được đặt nghi vấn. Đây là hai ví dụ. 

Năm 2005, nhóm chuyên gia điểu cầm học ở Cornell cho rằng đã tìm thấy một cá thể chim Ivory-billed Woodpecker (*Campephilus principalis*), một loài được tưởng chừng đã tuyệt chủng. Giả thuyết như sau:  

$$H_0: \text{Loài Ivory-billed Woodpecker đã tuyệt chủng.} $$

Chỉ cần một quan sát là có thể phản bác giả thuyết này. Tuy nhiên, nhiều người nghi ngờ bằng chứng đó. Mặc dù đã có cuộc tìm kiếm và giải thường \$50.000 cho thông tin mẫu sống, không bằng chứng nào thoả mãn được điều kiện đã đưa ra (tới năm 2015). Ngay khi một bằng chứng sống có xuất hiện, câu chuyện này là một ví dụ ngược với câu chuyện thiên nga. Tìm một trường hợp ngược với giả thuyết thường đi kèm với khó khăn trong quan sát. Thiên nga đen không phải lúc nào cũng là thiên nga đen, cũng có lúc thiên nga trắng là thiên nga đen. Đây là xác nhận sai (dương tính giả) và phủ nhận sai (âm tính giả). Trong bối cảnh khó khăn trong quan sát này, những nhà khoa học mà tin loài Ivory-billed Woodpecker đã tuyệt chủng sẽ luôn nghi ngờ một phản bác mới đưa ra. Những người tin rằng nó còn tồn tại thường đếm luôn những trường hợp mơ hồ để thực hiện phản bác.

Một ví dụ khác trong vật lý học, tập trung vào tìm kiếm hạt nhanh hơn ánh sáng neutrino.<sup><a name="r12" href="#12">12</a></sup> Vào tháng 9/2011, một đội ngũ nhà vật lý công bố đã tìm được hạt neutrino - nhỏ, hạt trung tính dưới mức nguyên tử, xuyên thấu mạnh và không gây hại - có thể di chuyển đến Switzerland từ Italy nhanh hơn ánh sáng. Theo Einstein, neutrino không thể đi nhanh hơn tốc độ ánh sáng. Có vẻ đây là một trường hợp phản bác của thuyết tương đối. Nếu đúng như vậy, nó sẽ làm đảo lộn cả giới vật lý.  

Phản ứng chung của giới vật lý bấy giờ không phải là "Einstein sai rồi!", mà là "Nhóm bạn đã tính sai như thế nào rồi?" Ngay cả bản thân nhóm công bố cũng có phản ứng tương tự, và tự hỏi, kiểm tra các phép tính và tái lập lại kết quả.  

Kết quả đo lường đã bị sai ở đâu? Bạn nghĩ rằng việc đo tốc độ chỉ đơn giản là lấy quãng đường chia thời gian. Nó đúng là vậy, nhưng tồn tại ở quy mô và trạng thái năng lượng cơ bản mà bạn đang sống. Nhưng với những hạt cơ bản như neutrino, nếu bạn đo tại thời điểm nó bắt đầu di chuyển, bạn đã thất bại. Hạt đã tiêu biến ngay khi bạn vừa đo xong. Cho nên cần cách tiếp cận khác. Hiệu thời gian so với tốc độ ánh sáng cũng rất nhỏ, cho nên độ trễ thời gian từ lúc nhận tín hiệu cho đến hệ thống cũng có thể bị khuếch đại nhiều lần. Và thực tế "phép đo đạc" này là kết quả rút ra từ mô hình thống kê, bây giờ mô hình này phải được rà soát lại. Năm 2013, giới vật lý hoàn toàn tin rằng kết quả hạt nhanh hơn ánh sáng Neutrino là do sai sót trong đo lường. Họ đã tìm ra lỗi kỹ thuật, trong đó bao gồm do một sợi cáp không được hàn gắn tốt.<sup><a name="r13" href="#13">13</a></sup> Hơn thế, hạt neutrino từ các vụ supernova tuân theo nguyên lý của Eistein, và khoảng cách ấy lớn hơn nhiều và cũng cho kết quả hiệu tốc độ tốt hơn.  

Trong vở kịch woodpecker và neutrino, chìa khoá gây phân vân chính là mệnh đề phản bác có thực sự tồn tại hay không. Đo lường trong cả hai trường hợp này đều phức tạp, nhưng ở hai hướng khác nhau, về mặt phát hiện đúng và phát hiện sai. Popper cũng nhận ra giới hạn này trong đo lường, nên ông nhìn khoa học rộng hơn so với phản bác đơn thuần. Nhưng bản chất xác suất tự nhiên của bằng chứng hiếm khi được bàn đến trong các buổi thảo luận triết học và thực hành phản bác.<sup><a name="r14" href="#14">14</a></sup> Tôi đã đọc nhiều sách lịch sử khoa học và thấy rằng những vấn đề về đo lường là thường gặp, chứ không phải ngoại lệ.<sup><a name="r15" href="#15">15</a></sup>

#### 1.2.2.2 Giả thuyết có tính định lượng

Một vấn đề khác trong câu chuyện thiên nga là giả thuyết không phải lúc nào cũng "tất cả thiên nga đều trắng", mà đại loại như vậy:

$$ H_0: \text{80% thiên nga là trắng} $$

<center>hoặc:</center>

$$ H_0: \text{thiên nga đen hiếm gặp} $$

Vậy giờ ta kết luận như thế nào, sau khi quan sát được một con thiên nga đen? Giả thuyết vô hiệu không đề cập thiên nga đen không tồn tại, mà chỉ là một tần suất. Công việc ở đây không phải là bác bỏ hay chứng minh giả thuyết này, mà là ước lượng và diễn giải phân phối của màu sắc thiên gia càng chính xác càng tốt. Ngay khi không có sai sót trong đo lường, vấn đề này sẽ không cho chúng ta dùng logic *'modus tollens'* của câu chuyện thiên nga vào khoa học của chúng ta.<sup><a name="r16" href="#16">16</a></sup>

Bạn có thể nói rằng giả thuyết trên là một giả thuyết kém chất lượng, tại vì nó quá khó để bác bỏ. Nhưng nếu đúng vậy, thì đa số câu hỏi quan trọng của thế giới đều kém. Do đó, định nghĩa về "giả thuyết tốt" không có giúp đỡ gì nhiều. Ngày nay, hầu hết mọi người cho rằng một thực hành tốt là thiết kế thí nghiệm và quan sát mà có thể phân biệt dễ dàng giữa các giả thuyết. Nhưng với nhiều trường hợp, sự so sánh phải mang tính xác suất, một vấn đề về định lượng, không phải định tính.<sup><a name="r17" href="#17">17</a></sup>

### 1.2.3 Đồng thuận trong phản bác

Giới khoa học vẫn có những đồng thuận trong một số công cuộc phản bác giả thuyết. Thuyết nhiệt lượng và mô hình địa tâm không còn được dạy trong giáo dục, ngoại trừ lúc dạy tại sao nó bị phản bác, và bằng chứng đi theo. Và đa số các bằng chứng - không phải luôn luôn - có một chút vai trò cho hành động phản bác đó.

Nhưng việc phản bác phải luôn luôn được *đồng thuận*, chứ không phải là *phù hợp logic*. Khi **sai sót do đo lường** và **bản chất định lượng** của hiện tượng tự nhiên được quan tâm, giới khoa học luôn tranh cãi để đi đến sự đồng thuận về ý nghĩa của chứng cứ. Những cuộc tranh cãi này rất hỗn độn. Thậm chí một số sách lại trình bày lịch sử để nó giống như là phản bác về mặt logic.<sup><a name="r18" href="#18">18</a></sup> Những cuốn sách này có thể gây tổn hại, nhất là các nhà khoa học, bằng cách cho thấy sản phẩm của họ không thể vượt qua tiền nhân được. Nó làm cho khoa học có vẻ dễ dãi, bằng cách đưa ra những mô hình kém cõi. Nó cũng có thể hại đến cộng đồng, bằng cách phóng đại định nghĩa về kiến thức khoa học.<sup><a name="r19" href="#19">19</a></sup>

## <center>1.3 Các công cụ để tạo golem</center><a name="a3"></a>

Nếu phản bác là không phải hướng tiếp cận thống kê tốt, ta có thể làm gì? Làm mô hình. mô hình có dùng để thực hiện kiểm định - mọi phép kiểm thống kê đều là mô hình<sup><a name="r20" href="#20">20</a></sup> - và mô hình cũng dùng để đo lường, dự báo, và tranh luận. Thực hành nghiên cứu sẽ có lợi ích từ khả năng chế tạo và điều khiển mô hình, bởi vì rất nhiều câu hỏi khoa học mang tính chất tổng quát hơn "kiểm định" và những golem làm sẵn bạn có thể gặp trong các khoá học không phù hợp với nhiều bối cảnh nghiên cứu. Bạn có thể không biết nên dùng mô hình thống kê nào để dùng, trừ phi bạn biết sẵn mô hình xử lý tạo dữ liệu.

Nếu bạn muốn giảm nguy cơ phá huỷ Prague, thì bạn phải biết kỹ thuật chế tạo golem. Bạn phải nhớ rằng: Bạn vẫn sẽ từ từ phá huỷ Prague. Nhưng nếu bạn là một kỹ sư golem tốt, bạn sẽ phát hiện sớm điều đó. Và vì bạn biết golem hoạt động như thế nào, bạn sẽ nhận ra sai sót ở đâu. Ít ra golem tiếp theo sẽ không tệ hơn. Nếu không được học cách tạo golem, bạn sẽ lúc nào cũng bị lệ thuộc bởi một ai đó.  

Ta dùng mô hình cho nhiều mục đích khác nhau: thiết kế form thông tin, chiết xuất thông tin từ dữ liệu, và tạo dự đoán. Các công cụ để đạt được mục đích này là:
1. Phân tích Bayes
2. So sánh mô hình
3. Mô hình đa tầng
4. Mô hình sơ đồ nhân quả

Những công cụ này liên quan mật thiết với nhau, nên thường được dạy chung. Để hiểu được những công cụ này, cần phải thực hành vào thực tế - bạn không thể hiểu kỹ thuật tạo golem cho đến khi bạn làm nó. Cho nên sách này tập trung vào code, và từng bước các kỹ thuật.

## 1.3.1 Phân tích Bayes

Giả sử bạn có data, bạn sẽ dùng nó như thế nào để hiểu biết thêm về thế giới? Không có trả lời chính xác cho câu hỏi này. Có rất nhiều cách tiếp cận, cả về mặt học thuật và cảm tính, đều hiệu quả. Nhưng một trong những cách tiếp cận hiệu quả và tổng quát nhất là dùng phân tích Bayes. Phân tích Bayes nhận câu hỏi dưới dạng mô hình và sử dụng logic để cho trả lời dưới dạng phân phối xác suất.

Nói thẳng ra, phân tích Bayes không khác gì phép đếm số lần xảy ra dựa trên giả định ban đầu. Thứ có thể xảy ra trong nhiều tình huống thì càng đáng tin hơn. Và thuyết xác suất liên quan đến phép đếm bởi xác suất chẳng qua là đạo hàm của phép đếm. Nó cho phép ta có thể dùng thuyết xác suất như là một phương pháp tổng quát để đại diện cho tính phù hợp, cho dù để mô tả những sự kiện đếm được ở thế giới thực hay những con số trừu tượng hơn như tham số (parameter). Mọi thứ còn lại đều theo logic. Khi bạn đặt ra được mô hình thống kê, phân tích Bayes đưa ra phương pháp thuần logic để xử lý data từ đó cho ra kết quả suy luận.

Nó sẽ có ích nếu ta có một cách tiếp cận khác để so sánh phân tích Bayes. Xác suất Bayes là một phương pháp tiếp cận xác suất, và nó bao gồm một trường hợp đặc biệt, một phướng pháp tiếp cận khác, tiếp cận theo hướng **FREQUENTIST**. Cách tiếp cận theo frequentist yêu cầu mọi xác suất được định nghĩa thông qua mối liên hệ giữa tần suất của sự kiện trong mẫu quan sát có số lượng cực lớn.<sup><a name="r21" href="#21">21</a></sup> Điều này làm cho tính bất định trong frequentist phải dựa vào các mẫu được tái chọn một data tưởng tượng - nếu ta lặp lại phép đo lường rất rất nhiều lần, bạn sẽ thu thập được một danh sách các giá trị có một vài khuynh hướng trong đó. Điều đó có nghĩa tham số và mô hình không có được phân phối xác suất, chỉ có giá trị đo lường mới có. Phân phối của các giá trị đo lường đó gọi là **phân phối mẫu (SAMPLING DISTRIBUTION)**. Nhưng việc tái chọn mẫu thực tế là không xảy ra, và thậm chí nó rất vô lý - không thể nào bạn tái thu thập mẫu của quần thể đa dạng các loài chim tại vùng núi Andes. Theo Ronald Fisher, nhà thống kê nổi tiếng bậc nhất theo frequentist ở thế kỷ 20, từng nói:<sup><a name="r22" href="#22">22</a></sup>

<blockquote cite="https://psycnet.apa.org/record/1957-00078-000">
    <p>[...] những quần thể chỉ được nói đến khi áp dụng trong phép kiểm định không có tồn tại thực thể, chỉ xuất hiện do kết quả trí tưởng tượng của nhà thống kê [...]</p>
</blockquote>

Trong nhiều bối cảnh, như thực nghiệm kiểm soát nhà kính, nó là một dụng cụ hữu ích để mô tả tính bất định. Cho dù bối cảnh nào, nó là một phần của mô hình, một giả định về data sẽ có hình dạng như thế nào dưới việc tái chọn mẫu. Nó tuyệt vời cũng như cách Bayes dùng xác suất để mô tả mọi loại tính bất định, cho dù nó là cảm tính hay học thuật.<sup><a name="r23" href="#23">23</a></sup>

Nhưng thái độ dành cho xác suất khác nhau dẫn đến sự đánh đổi khác nhau. Xem xét ví dụ sau đây để so sanh sự khác nhau giữa xác suất Bayes và frequentist. Vào năm 1610, Galileo dùng kính thiên văn sở khởi nhìn vào bầu trời và là người đầu tiên thấy được Vành đai của sao thổ. Có lẽ ông ta đã nhìn thấy một hình cầu, với nhiều hình cầu nhỏ gắn trên nó.([**HÌNH 1.3**](#f3))

<a name="f3"></a>![](/assets/images/fig 1-3.png)
<details class="fig"><summary>Hình 1.3: Sao Thổ, giống như Galileo đã nhìn thấy. Hình dáng thật chưa được chắc chắn, nhưng không phải do biến thiên từ việc lấy mẫu. Thuyết xác suất vẫn có thể giúp đỡ.</summary></details>

Bởi vì kính thiên văn đó còn nguyên thuỷ, cho nên chất lượng ảnh chắc chắn chưa tốt. Sao thổ sẽ được nhìn không rõ ràng. Đây là một dạng vấn đề của xác suất. Tồn tại một tính bất định về hình dạng của hành tinh, nhưng để ý thấy rằng không có tính bất định nào là do biến thiên của quan sát lặp lại. Cho dù bạn nhìn qua kính một ngàn lần, nó vẫn cho hình ảnh mờ ảo tương tự (với cặp vị trí Trái Đất và Sao Thổ). Cho nên phân phối mẫu cho bất kỳ đo lường là hằng định, bởi vì đo lường có tính quyết định - không có ngẫu nhiên từ nó. Suy luận thống kê frequentist có rất nhiều khó khăn khi bắt đầu từ đây. Ngược lại, suy luận Bayes vẫn được tiến hành như bình thường, bởi vì "nhiễu (noise)" có tính quyết định này vẫn có thể được mô hình hoá bằng xác suất, miễn là bạn đừng xác định xác suất bằng tần suất. Kết quả là, thuật toán Bayes chiếm ưu thế trong lĩnh vực tái tạo và xử lý hình ảnh.<sup><a name="r24" href="#24">24</a></sup>

Trong những quy trình phổ biến hơn, như hồi quy tuyến tính, sự khác nhau giữa hai hệ tư tưởng xác suất không có tác động nhiều. Tuy nhiên, mặc dù quy trình Bayes và frequentist cho cùng kết quả, bạn phải nhận ra rằng golem Bayes không cho suy luận dựa trên phương pháp tái chọn mẫu tưởng tượng. Khái quát hơn, golem Bayes xem "sự ngẫu nhiên" như đặc trưng của thông tin, không phải của thế giới thực. Không có gì ở thế giới thực - ngoài trừ những diễn đạt mâu thuẫn trong vật lý học lượng tử - là ngẫu nhiên. Giả sử, nếu chúng ta có nhiều thông tin hơn, bạn có thể dự đoán tất cả mọi thứ. Bạn chỉ sử dụng yếu tố ngẫu nhiên để mô tả tính bất định khi đối diện với sự thiếu hụt kiến thức. Dưới góc nhìn của golem, đồng xu được tung "ngẫu nhiên", nhưng thực sự golem là ngẫu nhiên, không phải đồng xu.

Chú ý rằng những mô tả trước không hề nhắc gì đến "niềm tin" cá nhân hay ý kiến chủ quan. Phân tích Bayes là chỉ một quy trình logic để xử lý thông tin. Có một truyền thống sử dụng quy trình này như một tiêu chuẩn mô tả niềm tin để giải biện, gọi là **BAYESIANISM**.<sup><a name="r25" href="#25">25</a></sup> Nhưng cuốn sách này không mô tả hay giảng dạy nó. Thực vậy, tôi nghĩ rằng không một phương pháp thống kê nào, Bayes hoặc ngược lại, tự mình nó là đủ.

Trước khi qua công cụ tiếp theo, tôi muốn nhấn mạnh lợi thế của phân tích Bayes, chí ít khi mọi người bắt đầu học thiết kế mô hình. Toàn bộ sách này có thể viết mà không nhắc đến "Bayes". Nó có thể đơn giản hơn, hoặc có thể khó hơn. Nhưng tôi đã học thống kê ở cả hai phương pháp tiếp cận, và nhận ra rằng thống kê Bayes được trình bày ở dạng dễ hiểu hơn. Có lẽ bằng chứng tốt nhất là rất nhiều nhà khoa học diễn giải kết quả không phải Bayes (non-Bayes) như là trong Bayes, ví dụ như trị số *p*-value và khoảng tin cậy non-Bayes được diễn giải lần lượt như xác suất hậu nghiệm (posterior) và khoảng tin cậy Bayes. Ngay cả giảng viên thống kê cũng mắc lỗi này.<sup><a name="r26" href="#26">26</a></sup> Nhà thống kê có vẻ luôn phải nhắc nhở cảnh báo *p*-value ở mọi bài báo. Ở một suy nghĩ khác, mô hình Bayes cho phép diễn giải trực quan hơn, mà nhà khoa học thường hay ánh xạ vào kết quả thống kê của họ. Sai lầm ngược lại - diễn giải xác suất posterior như *p*-value - rất hiếm xảy ra.

Điều này không nói lên mô hình Bayes thì đúng hơn mô hình non-Bayes. Điều này nghĩa là về mặt trực quan của nhà khoa học sẽ đồng hành với logic của quy trình. Điều này sẽ làm cho việc học thiết kế mô hình dễ dàng hơn.

<div class="alert alert-info">
    <p><strong>Xác suất không chỉ có một định nghĩa.</strong> Sẽ rất khó chịu khi được nghe rằng "xác suất" có nhiều định nghĩa. Các quan điểm toán học có chính xác tuyệt đối không? Không. Khi bạn quen dần với vài định nghĩa căn bản, hay giả định ban đầu, mọi thứ sau đó sẽ suông sẻ về mặt logic toán học. Nhưng giả định ban đầu là giả định mở để mọi người tranh luận và diễn giải. Cho nên không chỉ có xác suất "Bayes" và "frequentist", trong xác suất Bayes còn có phiên bản định nghĩa khác, dựa trên những quan điểm khác nhau để hướng dẫn phương pháp tiếp cận. Trong những bài viết nâng cao hơn về Bayes, bạn sẽ gặp những tên như Bruno de Finetti, Richard T.Cox, và Leonard "Jimmie" Savage. Những hình tượng này liên quan đến những quan điểm khác nhau của xác suất Bayes. Và còn nhiều hơn nữa. Sách này chủ yếu diễn giải theo logic Cox (hay Laplace-Jefreys-Cox-Jaynes).</p>
    <p>Vậy những diễn giải xác suất khác nhau tự sống sót ra sao? Bản thân những quan điểm toán học không có ý nghĩa gì, dưới ánh mắt của ứng dụng thực tế. Lấy căn bậc hai của số âm nghĩa là gì? Tìm ra tiệm cận giới hạn khi một hàm số khi nó tiến tới vô cực nghĩa là gì? Đây là những khái niệm cần thiết và được sử dụng hàng ngày, nhưng ý nghĩa của nó phải dựa vào tình huống và người sử dụng, dựa trên khái niệm trừu tượng đó đại diện cho thực tế như thế nào. Toán học không tiếp cận trực tiếp thế giới thực. Cho nên trả lời câu hỏi như vậy là một dự án màu mỡ và hấp dẫn, trong tất cả nhánh của toán học thực hành. Vậy nên khi mọi người cùng chung tiên đề xác suất, không phải tất cả mọi người trong mọi tình huống đều đồng ý cách diễn giải xác suất.</p>
</div>

<div class="alert alert-info">
    <p><strong>Một chút lịch sử</strong>Phân tích Bayes tồn tại rất lâu, hơn cả những công cụ kinh điển trong thống kê cơ bản được phát triển ở đầu thế kỷ 20. Các phiên bản của tiếp cận Bayes được áp dụng trong khoa học vào cuối thế kỷ 17 cho đến thế kỷ 19. Nhưng sau Thế Chiến Thứ Nhất, nhà thống kê anti-Bayes, như Ronald Fisher, đã thành công diễn giải hướng tiếp cận của ông. Tất cả lời Fisher nói về phân tích Bayes (thời đó gọi là xác suất ngược (inverse probability)) trong cuốn sách nổi tiếng 1925 của ông:<sup><a name="r27" href="#27">27</a></sup>
        <blockquote cite="Statistical Methods for Research Workers">
            <p>[...] Thuyết xác suất ngược được xây dựng dựa một lỗi sai, và phải được loại bỏ.</p>
        </blockquote>
    </p>
    <p>Phân tích Bayes trở nên được chấp nhận nhanh chóng ở nửa sau thế kỷ 20, bởi nó được chứng minh không phải được xây dựng trên lỗi sai. Ngoài triết lý đằng sau nó, tất cả những nguyên tắc bên trong đều hoạt động tốt. Đầu thập niên 1990, các phương pháp tính toán trên máy tính dẫn tới sự phát triển bùng nổ trong ứng dụng phương pháp Bayes.<sup><a name="r28" href="#28">28</a></sup> Tuy nhiên, phương pháp Bayes vẫn cần máy tính cấu hình mạnh. Và với kích thước dữ liệu khổng lồ hơn - hàng triệu dòng là bình thường trong phân tích gen - những phương pháp ước lượng cho suy luận Bayes rất quan trọng, trong hiện tại và tương lai.</p>
</div>

### 1.3.2 So sánh mô hình và khả năng dự đoán.

Phân tích Bayes cho phép mô hình học từ data. Nhưng khi có nhiều mô hình thống kê khác nhau cũng phù hợp như nhau, thì ta nên chọn mô hình nào? Câu trả lời có thể là chọn mô hình cho dự đoán chính xác nhất. Sau trả lời có nhiều câu hỏi mới được đặt ra, bởi vì để chọn mô hình có dự đoán tốt, ta cần phải biết tương lai. Có 2 công cụ liên quan, và chúng đều không cần biết tương lai: **CROSS VALIDATION** và **INFORMATION CRITERIA**. Những công cụ này dùng để so sánh mô hình với nhau dựa vào ước lượng độ chính xác của dự đoán.

Bản thân việc so sánh mô hình dựa trên độ chính xác của dự đoán rất có ích. Nó còn hữu ích hơn nữa vì nó giúp ta phát hiện được một hiện tượng tuyệt vời: Mô hình phức tạp cho dự đoán tệ hơn mô hình đơn giản. Nghịch lý (Paradox) chính của dự đoán này là **OVERFITTING**.<sup><a name="r29" href="#29">29</a></sup> Data trong tương lại không chắc gì sẽ giống data trong quá khứ, và nếu hình nào không chú ý thực tế này sẽ cho kết quả dự đoán tệ hơn. Và mô hình càng phức tạp thường dễ bị overfitting hơn những mô hình đơn giản - golem càng thông minh, dự đoán của nó càng ngu ngốc. Cho nên nếu bạn muốn cho kết quả dự đoán tốt, ta không thể đánh giá mô hình dựa vào cách nó fit data tốt như thế nào. *Fit thì dễ, dự đoán thì khó.*

Cross-validation và information criteria giúp chúng ta theo 3 cách:
1. Chúng cung cấp những ước lượng hữu ích cho độ chính xác của dự đoán, hơn là đơn thuần chỉ fit cho mẫu quan sát. Cho nên chúng so sánh mô hình dựa tác dụng của mô hình. 
2. Chúng ta ta uớc lượng tình trạng overfitting của mô hình. Điều này giúp ta hiểu thêm sự tương tác giữa mô hình và data, và giúp thiết kế mô hình tốt hơn.
3. Chúng giúp ta tìm ra data nào có mức độ ảnh hưởng lớn.

Phân tích Bayes đã hoạt động tốt trong hàng thập kỷ. Information criteria thì còn non trẻ nhưng đang phát triển rất nhanh. Nhiều nhà thống kê chưa bao giờ dùng information criteria vào ứng dụng thực tế, và cũng không có khuyến cáo thước đo nào là tốt nhất và dùng như thế nào. Dẫu vậy, khoa học đã và đang dùng information criteria rất thường xuyên, xuất hiện trong các bài báo và tranh luận nổi tiếng.<sup><a name="r30" href="#30">30</a></sup> Sức mạnh của nó thường được phóng đại, và chúng ta phải cẩn thận chú ý những khả năng chúng làm được cũng như không làm được.

<div class="alert alert-info">
    <p><strong>Neanderthal trong người bạn.</strong> Ngay cả mô hình đơn giản đôi khi cũng cần có biện pháp thay thế. Năm 2010, bộ gen nháp của người Neanderthal cho biểu hiện có nét chung với người không gốc Phi hơn là người gốc Phi. Dấu hiệu còn được thấy ở con lai giữa Neanderthal và người hiện đại, những người di cư từ Châu Phi. Tuy nhiên, phát hiện trình tự DNA giống nhau giữa người Châu Âu hiện đại và Neanderthal là không đủ để nói rằng là có hiện tượng lai.<sup><a name="r31" href="#31">31</a></sup> Nói ngắn gọn là, nếu người cổ đại Đông Bắc Phi có trình tự DNA riêng, thì Neanderthal và người Âu hiện đại vẫn có trình tự này từ tổ tiên, hơn là do lai. Câu chuyện đơn giản như ước lượng người Neanderthal và người hiện đại có chung đoạn mã DNA độc nhất hay không, vẫn có nhiều cách giải thích từ mô hình xử lý. So sánh mô hình là cần thiết trong trường hợp này.</p>
</div>

### 1.3.3  Mô hình đa tầng

Trong truyền thuyết vũ trụ Hindu, Trái Đất được đặt trên lưng của một con voi lớn, con voi thì đứng trên lưng của con rùa khổng lồ. Khi hỏi con rùa đứng trên cái gì, người ta trả lời rằng, "Nó đứng trên một con rùa khác và theo dưới nó cũng vậy".  

Mô hình không có con rùa nào ở đây, nhưng nó có tham số giúp cho suy luận. Vậy tham số đứng trên đâu? Đôi khi, trong vài mô hình lớn, tham số đứng chồng lên tham số khác luôn. Ý ở đây là với một tham số bất kỳ, nó có thể là một con số tạm của một mô hình bị ẩn. Với một mô hình trả giá trị một tham số, ta có thể lồng ghép mô hình trả giá trị tham số đó vào một mô hình có sẵn. Kết quả là mô hình với rất nhiều tầng chứa tính bất định, mỗi tầng trả tham số của tầng tiếp theo. Đây là một **mô hình đa tầng (MULTILEVEL MODEL)**.  

Mô hình đa tầng - hay còn gọi là phân tầng, hiệu ứng ngẫu nhiên, hiệu ứng biến thiên, hay hiệu ứng hỗn hợp (hierarchical, random effects, varying effects, or mixed effects) đang trở thành mốt thời thượng trong khoa học sinh học và xã hội học. Lĩnh vực đa dạng khác như kiểm định giáo dục và phân chủng vi khuẩn hiện nay đã sử dụng mô hình đa tầng để xử lý data. Giống phân tích bayes, thiết kê mô hình đa tầng là không mới. Nhưng nó mới xuất hiện trên máy tính ở vài thập kỷ nay. Và do mô hình đa tầng mang tính chất của Bayes, nó đã đang phát triển tay trong tay với phân tích Bayes.

Một lý do để quan tâm mô hình đa tầng là bởi vì chúng cho phép giải quyết overfitting. Cross-validation và information criteria cho phép đo lường và nhận ra nguy cơ overfitting. Mô hình đa tầng thực chất là người giải quyết nó. Mô hình đa tầng dùng một kỹ thuật tuyệt vời là **góp bán phần (PARTIAL POOLING)**, để góp thông tin từ nhiều đơn vị trong data để tạo ra ước lượng tốt hơn cho toàn bộ đơn vị.

Partial pooling là công nghệ chính, và phù hợp với nhiều bối cảnh đa dạng. Có bốn tình huống thường gặp.
1. *Để thay đổi ước lượng khi tái chọn mẫu.* Khi một hay nhiều quan sát phát xuất từ một cá thể, địa điểm, thời gian, thì mô hình đơn tầng cổ điển có thể làm ta diễn giải nhầm.
2. *Để thay đổi ước lượng trong mẫu không cân bằng.* Khi một số cá thể, địa điểm hoặc thời gian được chọn mẫu nhiều lần hơn so với còn lại, ta có thể diễn giải nhầm.
3. *Để nghiên cứu sự biến thiên.* Nếu nghiên cứu gồm sự biến thiên trong các cá thể hoặc nhóm khác trong dữ liệu, thì mô hình đa tầng rất có ích, vì nó mô phỏng trực tiếp sự biến thiên.
4. *Để tránh hiện tượng trung bình hoá.* Thông thường, người ta sẽ trung bình hoá dữ liệu để tạo biến số cho phân tích hồi quy. Việc này có thể nguy hiểm, bởi việc trung bình hoá làm mất đi tính biến thiên, và gây ra độ tin cậy giả. Mô hình đa tầng cho ta giữ nguyên tính bất định của dữ liệu, trong khi vẫn cho ta dùng con số trung bình để dự đoán.

Bốn tình huống trên được áp dụng vào bối cảnh nhà nghiên cứu nhận ra có các phân cụm có thể khác nhau với phân cụm còn lại khác. Phân cụm này có thể là cá nhân như những học sinh khác nhau, vị trí địa lý như thành phố khác nhau, hoặc thời gian như năm khác nhau. Vì mỗi phân cụm có khuynh hướng trung bình khác và đáp ứng điều trị khác nhau, dữ liệu phân cụm thường được phân tích hiệu quả hơn khi được mô hình hoá bởi golem có khả năng sử dụng sự biến thiên này.

Nhưng tầm nhìn của mô hình đa tầng còn hơn thế nữa. Rất nhiều dạng mô hình thực chất là mô hình đa tầng: mô hình tạo dữ liệu bị mất (imputation), sai số do đo lường, phân tích yếu tố, vài mô hình chuỗi thời gian, các loại hồi quy không gian và mạng, hồi quy phân nhóm gen là những ứng dụng đặc biệt của chiến thuật mô hình đa tầng. Trong một số quy trình thống kê thường gặp, như *t*-test bắt cặp, thực sự là mô hình đa tầng nguỵ trang thành. Nắm vững các khái niệm của thiết kế mô hình đa tầng có thể dẫn đến một cuộc cách mạng trong suy nghĩ. Đột nhiên bạn sẽ thấy mô hình đơn tầng giống như một bộ phần của mô hình đa tầng. Chiến thuật mô hình đa tầng cung cấp một nguyên tắc thiết kế mô hình để giúp chúng ta lồng ghép các bộ phần đó vào phân tích cụ thể, chính xác theo những gì ta suy nghĩ và cần thiết.

Tôi muốn độc giả chấp nhận một điều phi lý này: *hồi quy đa tầng nên là dạng mặc định của hồi quy*. Những bài báo không dùng mô hình đa tầng nên phải giải thích rõ là tại sao không dùng cách tiếp cận đa tầng. Dĩ nhiên là vẫn có data và tình huống không cần dùng mô hình đa tầng. Nhưng đa số nghiên cứu sinh học và xã hội học hiện nay, cho dù có thực nghiệm hay không, đều có lợi từ nó. Có lẽ lý do quan trọng nhất là ngay với điều trị được kiểm soát tốt, vẫn có tương tác với sai số không đo được của cá thể, nhóm hay quần thể nghiên cứu. Điều này dẫn đến biến thiên trong hiệu ứng điều trị, trong đó cá thể và nhóm thay đổi đáp ứng của họ trong tình huống như nhau. Mô hình đa tầng tìm cách để định lượng mức độ biến thiên đó, cũng như xác định đơn vị nào của dữ liệu đáp ứng theo con đường nào.

Những lợi ích này không miễn phí. Việc fit và diễn giải mô hình đa tầng khó hơn nhiều so với hồi quy truyền thống. Trong thực hành, nhà khoa học chỉ đơn thuần tin tưởng vào phần mềm hộp đen (black-box) và diễn giải hồi quy đa tầng như hồi quy đơn tầng. Theo thời gian, điều này sẽ thay đổi. Từng có một khoảng thời gian trong thực hành thống kê, hồi quy đa biến được xem là phương pháp cao cấp, chỉ những chuyên gia mới được thiết kế và sử dụng. Thay vào đó, nhà khoa học dùng nhiều các quy trình đơn giản hơn, như *t*-test. Ngày nay, hầu như mọi người đều dùng phương pháp đa biến. Điều tương tự cũng sẽ xảy ra với mô hình đa tầng. Văn hoá và trình độ học vấn vẫn còn nhiều thứ để bắt kịp.

<div class="alert alert-info">
    <p><strong>Mô hình dự đoán bầu cử đa tầng.</strong> Một trong những ứng dụng lâu đời nhất của mô hình đa tầng là dự đoán kết quả bầu cử tổng thống. Đầu thập niên 1960, John Tukey (1915-2000) bắt đầu làm việc cho Công ty Truyền hình Quốc gia (NBC) tại Mỹ, đã phát triển mô hình dự đoán bầu phiếu thời gian thực dựa trên nhiều loại dữ liệu: phiếu bầu, trúng cử trong quá khứ, kết quả bán phần, kết quả cuối tại các quận liên quan. mô hình này dùng khung thiết kế đa tầng. Tukey đã thiết kế và sử dụng mô hình này cho NBC đến năm 1978.<sup><a name="r32" href="#32">32</a></sup> Hiện nay dự đoán bầu cử và phân nhóm phiếu bầu vẫn là chủ đề hấp dẫn cho thiết kế đa tầng.<sup><a name="r33" href="#33">33</a></sup></p>
</div>

### 1.3.4 Mô hình sơ đồ nhân quả

Gió thổi, nhánh cây đung đưa. Nếu bạn là con người, thì sẽ nhận ra đây là mệnh đề nhân quả. Nhưng với chỉ có data, nó vẫn có thể là nhánh cây đung đưa tạo ra gió. Đây thực sự ngớ ngẩn, bởi nhánh cây không tự đung đưa được. Mô hình thống kê là một động cơ tương quan tuyệt vời. Nhưng nó không đủ để suy luận nhân quả, mô hình không phân biệt được là gió thổi làm nhánh cây đung đưa hay là nhánh cây đung đưa tạo ra gió. Những hiểu biết ngoài data là cần thiết để xem giải thích nào là đúng.

Cross-validation và information criteria cố gắng phỏng đoán độ chính xác của dự đoán. Như giới thiệu ở trên, overfitting là nghịch lý chính trong dự đoán. Bây giờ tác giới thiệu thêm một nghịch lý thứ hai: *Mô hình sai về mặt nhân quả, có thể cho dự đoán tốt hơn nhưng mô hình nhân quả thực sự.* Hệ quả, nếu bạn tập trung vào khả năng dự đoán, bạn sẽ dễ bị hiểu nhầm. Và nếu bạn nghĩ rằng *Thực nghiệm ngẫu nhiên có kiểm soát (randomized controlled trial)* cho phép suy luận nhân quả, thì thực ra nó vẫn có nguy cơ gây hiểu nhầm. Không ai an toàn cả.

Tôi sẽ gọi đây là vấn đề **XÁC ĐỊNH (IDENTIFICATION)** và phân biệt một cách cẩn thận nó với vấn đề dự đoán. Hãy xem xét hai định nghĩa khác nhau của "dự đoán". Đơn giản nhất khi ta là người quan sát và muốn biết cái gì sẽ xảy ra tiếp theo. Trong tình huống này, công cụ như cross-validation là rất hữu ích. Nhưng nó cũng sẵn sàng đề nghị những mô hình chứa biến gây sai lệch (confounder) và những quan hệ nhân quả gây hiểu nhầm. Tại sao? Confounder cũng tạo tương quan thật, và nó cũng giúp tăng độ chính xác dự đoán. Suy cho cùng, nếu bạn nhìn ra ngoài và thấy nhánh cây đung đưa, nó thực sự dự đoán có gió. Dự đoán chính xác không cần xác định nhân quả chính xác. Thực vậy, các bạn sẽ thấy trong chương sau, dự đoán có thể được cải thiện hơn nếu dùng mô hình gây hiểu nhầm về mặt nhân quả.

Nhưng sẽ xảy ra chuyện gì nếu ta can thiệp vào thế giới thực? Ta phải xem xét mặt thứ hai của "dự đoán". Giả sử ta cho nhiều người trèo lên cây và làm nhánh cây đung đưa, nó có tạo ra gió? Không nhiều lắm. 
Thông thường điểm chính của việc lập mô hình thống kê là tạo ra sự hiểu biết nhằm dẫn đến tổng quát hoá và ứng dụng. Trong trường hợp ấy, ta cần những thứ nhiều hơn dự đoán tốt, dưới sự vắng mặt của can thiệp. Chúng ta cũng cần hiểu quan hệ nhân quả chính xác. Nhưng so sánh mô hình dựa vào độ chính xác của dự đoán - *p-*value hay gì đó khác - sẽ không phải lúc nào cũng cho kết quả đúng được.

Vậy có thể làm gì hơn? Thứ chúng ta cần là một mô hình nhân quả có thể dùng để hướng dẫn thiết kế một hay nhiều mô hình thống kê với mục đích xác nhận quan hệ nhân quả. Như trong ví dụ trước về thuyết phát triển phân tử trung gian, một mô hình khoa học hoàn toàn chứa nhiều thông tin hơn là một mô hình thống kê được suy ra từ nó. Và thông tin mới này cho biết quan hệ nhân quả. Kết luận này cho phép thử nghiệm mô hình nhân quả thay thế. Những kết luận và phép thử dựa vào các chi tiết. Ví dụ như các định lý cơ học Newton có thể dự đoán chính xác hệ quả của các tác động cụ thể. Và chính sự chính xác của dự đoán nói cho ta biết các định lý này là đúng.

Thật không may, đa số công trình khoa học thiếu hụt mô hình chính xác như vậy. Thay vào đó, ta dùng những giả thuyết mơ hồ và cố gắng ước lượng hiệu ứng nhân quả cũng mơ hồ tương tự. Trong kinh tế, không có mô hình lượng nào cho dự đoán chính xác hiệu ứng của việc thay đổi đồng lương tối thiểu. Nhưng có tin tốt là ngay khi nếu bạn không có cụ thể chính xác mô hình nhân quả, ta vẫn có thể tìm một mô hình cho phép khám phá biến số nào ảnh hưởng nhân quả lên biến khác, và suy luận nhân quả từ nó. Nhà kinh tế có thể ước lượng hiệu ứng nhân quả từ việc thay đổi lương tối thiểu, ngay cả không có mô hình khoa học chính xác.

Phương pháp thông dụng nhất để phân biệt suy luận nhân quả với suy luận tương quan, xuất phát từ nửa đầu thế kỷ 20, nhưng sau đó được mở rộng gần đây thành môn khoa học đo lường, thiết kế thực nghiệm, khả năng tổng quát hoá kết quả từ các mẫu quan sát.<sup><a name="r34" href="#34">34</a></sup> Ta sẽ gặp chúng thông qua cách sử dụng **sơ đồ nhân quả (GRAPHICAL CAUSAL MODEL)**. Sơ đồ nhân quả đơn giản nhất là **sơ đồ có hướng không vòng lặp (DIRECTED ACYCLIC GRAPH) (DAG)**. Ta có thể tìm ra DAG, chúng không phải mô hình thống kê chi tiết. Nhưng chúng cho phép chúng ta phán đoán mô hình thống kê nào cung cấp suy luận nhân quả hợp lý, dưới giả định của DAG đó đúng.

Vậy DAG có từ đâu? Sự thật kinh hoàng là tính hợp lý của suy luận thống kê dựa trên những thông tin ngoài data. Chúng ta cần mô hình nhân quả để thiết kế cách thu thập data và cấu trúc của mô hình thống kê. Nhưng cấu trúc của mô hình nhân quả không thuần tuý là lĩnh vực thống kê, và phân tích thống kê không bao giờ xác nhận đúng tất cả các giả định của chúng ta. Không một con golem nào chấp nhận data trần trụi mà cho mô hình nhân quả đáng tin cậy, diễn giải đúng quan hệ nhân quả của các biến số. Việc chúng ta cần làm là tiếp tục làm khoa học.

<div class="alert alert-info">
    <p><strong>Causal salad:</strong> Phân tích nhân quả cần một mô hình nhân quả, phân biệt với mô hình thống kê. Đơn thuần data là không đủ. Các nhà khoa học cũng đồng ý chuyện đó. Phản ứng, tuy nhiên, thì đa dạng. Phản ứng bảo thủ nhất là mặc định "nhân quả" là không có lời giải, như thế giới sau cái chết.<sup><a name="r35" href="#35">35</a></sup> Phản ứng ít bảo thủ hơn cho rằng quan hệ nhân quả chỉ có thể được suy luận từ điều kiện ngẫu nhiên và kiểm soát rất khắc nghiệt. Như vậy sẽ có rất nhiều trở ngoại. Nhiều câu hỏi nghiên cứu có thể không bao giờ thực nghiệm được: tiến hoá của loài người là một ví dụ. Nhiều câu hỏi khác về mặt nguyên tắc có thể thực nghiệm được, nhưng không mang tính nhân đạo. Và cũng nhiều thí nghiệm chỉ cố gắng kiểm soát - bệnh nhân không phải lúc nào cũng uống thuốc của họ.</p>
    <p>Cách tiếp cận chiếm đa số trong nghiên cứu y sinh hay xã hội là <strong>CAUSAL SALAD</strong><sup><a name="r36" href="#36">36</a></sup>, tức là ném tất cả toàn bộ các biến số vào mô hình, quan sát sự thay đổi của ước lượng, và cố gắng giải thích quan hệ nhân quả. Cách tiếp cận này dựa trên quan điểm là chỉ có khi không đủ biến số là sẽ làm sai lệch quan hệ nhân quả. Tuy nhiên, biến số đưa thêm vào, tương tự, cũng làm sai lệch quan hệ nhân quả. Khi trộn causal salad, nó có thể cho dự đoán tốt, nhưng cũng có thể hiếu nhầm quan hệ nhân quả. Nếu bạn dùng mô hình đó để thực hiện can thiệp, mọi thứ sẽ lộn ngược hoàn toàn.</p>
</div>

## <center>1.4 Tổng kết</center><a name="a4"></a>

Chương này cho bạn các lập luận để suy nghĩ lại các triết lý thống kê và khoa học hiện đang phổ biến. Thay vì dùng nhưng công cụ black-box để kiểm định giả thuyết vô hiệu, ta nên học để xây dựng và phân tích những mô hình của hiện tượng không tồn tại trạng thái vô hiệu. Để ủng hộ mục đích này, chương này giới thiệu suy luận Bayes, so sánh mô hình, mô hình đa tầng, và sơ đồ nhân quả.

--- 

<details><summary>Endnotes</summary>
<ol class='endnotes'>
<li><a name="1" href="#r1">1. </a>I draw this metaphor from Collins and Pinch (1998), The Golem: What You Should Know about Science. It is very similar to E. T. Jaynes’ 2003 metaphor of statistical models as robots, although with a less precise and more monstrous implication.</li>
<li><a name="2" href="#r2">2. </a>There are probably no algorithms nor machines that never break, bend, or malfunction. A common citation for this observation is Wittgenstein (1953), Philosophical Investigations, section 193. Malfunction will interest us, later in the book, when we consider more complex models and the procedures needed to fit them to data.</li>
<li><a name="3" href="#r3">3. </a>See Mulkay and Gilbert (1981). I sometimes teach a PhD core course that includes some philosophy of science, and PhD students are nearly all shocked by how little their causal philosophy resembles that of Popper or any other philosopher of science. The first half of Ian Hacking’s Representing and Intervening (1983) is probably the quickest way into the history of the philosophy of science. It’s getting out of date, but remains readable and broad minded.</li>
<li><a name="4" href="#r4">4. </a>Maybe best to begin with Popper’s last book, The Myth of the Framework (1996). I also recommend interested readers to go straight to a modern translation of Popper’s earlier Logic of Scientific Discovery. Chapters 6, 8, 9 and 10 in particular demonstrate that Popper appreciated the difficulties with describing science as an exercise in falsification. Other later writings, many collected in Objective Knowledge: An Evolutionary Approach, show that Popper viewed the generation of scientific knowledge as an evolutionary process that admits many different methods.</li>
<li><a name="5" href="#r5">5. </a>Meehl (1967) observed that this leads to a methodological paradox, as improvements in measurement make it easier to reject the null. But since the research hypothesis has not made any specific quantitative prediction, more accurate measurement doesn’t lead to stronger corroboration. See also Andrew Gelman’s comments in a September 5, 2014 blog post: http://andrewgelman.com/2014/09/05/confirmationist-falsificationist-paradigmsscience/.</li>
<li><a name="6" href="#r6">6. </a>George E. P. Box is famous for this dictum. As far as I can tell, his first published use of it was as a section heading in a 1979 paper (Box, 1979). Population biologists like myself are more familiar with a philosophically similar essay about modeling in general by Richard Levins, “The Strategy of Model Building in Population Biology” (Levins, 1966).</li>
<li><a name="7" href="#r7">7. </a>Ohta and Gillespie (1996).</li>
<li><a name="8" href="#r8">8. </a>Hubbell (2001). The theory has been productive in that it has forced greater clarity of modeling and understanding of relations between theory and data. But the theory has had its difficulties. See Clark (2012). For a more general skeptical attitude towards “neutrality,” see Proulx and Adler (2010).</li>
<li><a name="9" href="#r9">9. </a>For direct application of Kimura’s model to cultural variation, see for example Hahn and Bentley (2003). All of the same epistemic problems reemerge here, but in a context with much less precision of theory. Hahn and Bentley have since adopted a more nuanced view of the issue. See their comment to Lansing and Cox (2011), as well as the similar comment by Feldman.</li>
<li><a name="10" href="#r10">10. </a>Gillespie (1977).</li>
<li><a name="11" href="#r11">11. </a>Lansing and Cox (2011). See objections by Hahn, Bentley, and Feldman in the peer commentary to the article.</li>
<li><a name="12" href="#r12">12. </a>See Cho (2011) for a December 2011 summary focusing on debates about measurement.</li>
<li><a name="13" href="#r13">13. </a>For an autopsy of the experiment, see (posted 2012) http://profmattstrassler.com/articles-and-posts/particlephysics-basics/ neutrinos/neutrinos-faster-than-light/opera-what-went-wrong/.</li>
<li><a name="14" href="#r14">14. </a>See Mulkay and Gilbert (1981) for many examples of “Popperism” from practicing scientists, including famous ones.</li>
<li><a name="15" href="#r15">15. </a>For an accessible history of some measurement issues in the development of physics and biology, including early experiments on relativity and abiogenesis, I recommend Collins and Pinch (1998). Some scientists have read this book as an attack on science. However, as the authors clarify in the second edition, this was not their intention. Science makes myths, like all cultures do. That doesn’t necessarily imply that science does not work. See also Daston and Galison (2007), which tours concepts of objective measurement, spanning several centuries.</li>
<li><a name="16" href="#r16">16. </a>The first chapter of Sober (2008) contains a similar discussion of modus tollens. Note that the statistical philosophy of Sober’s book is quite different from that of the book you are holding. In particular, Sober is weakly anti-Bayesian. This is important, because it emphasizes that rejecting modus tollens as a model of statistical inference has nothing to do with any debates about Bayesian versus non-Bayesian tools.</li>
<li><a name="17" href="#r17">17. </a>Popper himself had to deal with this kind of theory, because the rise of quantum mechanics in his lifetime presented rather serious challenges to the notion that measurement was unproblematic. See Chapter 9 in his Logic of Scientific Discovery, for example.</li>
<li><a name="18" href="#r18">18. </a>See the Afterword to the 2nd edition of Collins and Pinch (1998) for examples of textbooks getting it wrong by presenting tidy fables about the definitiveness of evidence.</li>
<li><a name="19" href="#r19">19. </a>A great deal has been written about the sociology of science and the interface of science and public interest. Interested novices might begin with Kitcher (2011), Science in a Democratic Society, which has a very broad topical scope and so can serve as an introduction to many dilemmas.</li>
<li><a name="20" href="#r20">20. </a>Yes, even procedures that claim to be free of assumptions do have assumptions and are a kind of model. All systems of formal representation, including numbers, do not directly reference reality. For example, there is more than one way to construct “real” numbers in mathematics, and there are important consequences in some applications. In application, all formal systems are like models. See http://plato.stanford.edu/entries/philosophymathematics/ for a short overview of some different stances that can be sustained towards reasoning in mathematical systems.</li>
<li><a name="21" href="#r21">21. </a>Most scholars trace frequentism to British logician John Venn (1834–1923), as for example presented in his 1876 book. Speaking of the proportion of male births in all births, Venn said, “probability is nothing but that proportion” (page 84). Venn taught Fisher some of his maths, so this may be where Fisher acquired his opposition to Bayesian probability. Regardless, it seems to be a peculiar English invention.</li>
<li><a name="22" href="#r22">22. </a>Fisher (1956). See also Fisher (1955), the first major section of which discusses the same point. Some people would dispute that Fisher was a “frequentist,” because he championed his own likelihood methods over the methods of Neyman and Pearson. But Fisher definitely rejected the broader Bayesian approach to probability theory. See Endnote 27.</li>
<li><a name="23" href="#r23">23. </a>This last sentence is a rephrasing from Lindley (1971): “A statistician faced with some data often embeds it in a family of possible data that is just as much a product of his fantasy as is a prior distribution.” Dennis V. Lindley (1923–2013) was a prominent defender of Bayesian data analysis when it had very few defenders.</li>
<li><a name="24" href="#r24">24. </a>It’s hard to find an accessible introduction to image analysis, because it’s a very computational subject. At the intermediate level, see Marin and Robert (2007), Chapter 8. You can hum over their mathematics and still acquaint yourself with the different goals and procedures. See also Jaynes (1984) for spirited comments on the history of Bayesian image analysis and his pessimistic assessment of non-Bayesian approaches. There are better non-Bayesian approaches since. [11]</li>
<li><a name="25" href="#r25">25. </a>Binmore (2009) describes the history within economics and related fields and provides a critique that I am sympathetic to.</li>
<li><a name="26" href="#r26">26. </a>See Gigerenzer et al. (2004).</li>
<li><a name="27" href="#r27">27. </a>Fisher (1925), page 9. See Gelman and Robert (2013) for reflection on intemperate anti-Bayesian attitudes from the middle of last century.</li>
<li><a name="28" href="#r28">28. </a>See McGrayne (2011) for a non-technical history of Bayesian data analysis. See also Fienberg (2006), which describes (among many other things) applied use of Bayesian multilevel models in election prediction, beginning in the early 1960s.</li>
<li><a name="29" href="#r29">29. </a>Silver (2012) calls overfitting the most important thing in statistics that you’ve never heard of. This reflects overfitting’s importance and how rarely it features in introductory statistics courses. Silver’s book is a well-written, non-technical survey of modeling and prediction in a range of domains.</li>
<li><a name="30" href="#r30">30. </a>See Theobald (2010) for a fascinating example in which multiple non-null phylogenetic models are contrasted.</li>
<li><a name="31" href="#r31">31. </a>See Sankararaman et al. (2012) for a thorough explanation, including why current evidence suggests that there really was interbreeding.</li>
<li><a name="32" href="#r32">32. </a>See Fienberg (2006), page 24.</li>
<li><a name="33" href="#r33">33. </a>See Wang et al. (2015) for a vivid example.</li>
<li><a name="34" href="#r34">34. </a>The biologist Sewall Wright (1889-1988) began developing his “path analysis” approach to causal inference in genetics around the year 1918. See Wright 1921. The next largest contributions came from Donald Rubin’s potential-outcomes approach Rubin (1974) and Judea Pearl’s more graphic approach (Pearl, 2000). A spirited, opinionated, and accessible overview is given by Pearl in his 2018 book (Pearl and MacKenzie, 2018).</li>
<li><a name="35" href="#r35">35. </a>Some philosophers and statisticians have held this view. Karl Pearson, one of the most important statisticians of the twentieth century, wrote: “Beyond such discarded fundamentals as ‘matter’ and ‘force’ lies still another fetish among the inscrutable arcana of modern science, namely, the category of cause and effect.” (Pearson, 1911, p. vi of 3rd edition) This quote is playful, but the book contains an entire chapter of “Contingency and Correlation” with a section titled “The Category of Association, as replacing Causation.” The general message was that “cause” is a primitive concept that science should grow beyond and replace with refined notions of association and variation.</li>
<li><a name="36" href="#r36">36. </a>The phrase “causal salad” comes from Jag Bhalla’s 2018 blog post: https://bigthink.com/errors-we-liveby/judea-pearls-the-book-of-why-brings-news-of-a-new-science-of-causes. The post reviews Pearl and MacKenzie (2018).</li>
</ol></details>